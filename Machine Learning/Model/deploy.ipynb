{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHxxu6cJgESz"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/obss/sahi/blob/main/demo/inference_for_yolov5.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmyzO26FgES0"
      },
      "source": [
        "## 0. Preperation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7bHSb4IgES1"
      },
      "source": [
        "- Install latest version of SAHI and YOLOv5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL23AMeVgES1"
      },
      "outputs": [],
      "source": [
        "!pip install -U torch sahi yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZJIwyFugES2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d37640fc-c258-4f5e-ad00-57e82d218a54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njwsNyRdgES2"
      },
      "source": [
        "- Import required modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yc5GdbbFgES2"
      },
      "outputs": [],
      "source": [
        "# arrange an instance segmentation model for test\n",
        "from sahi.utils.yolov5 import (\n",
        "    download_yolov5s6_model,\n",
        ")\n",
        "\n",
        "# import required functions, classes\n",
        "from sahi import AutoDetectionModel\n",
        "from sahi.utils.cv import read_image\n",
        "from sahi.utils.file import download_from_url\n",
        "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEctw4fggES2"
      },
      "source": [
        "- Download a yolov5 model and two test images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKpz2mYFgES3"
      },
      "outputs": [],
      "source": [
        "yolov8_model_path = 'models/best.pt'\n",
        "download_yolov5s6_model(destination_path=yolov8_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7GUQ894gES3"
      },
      "source": [
        "## 1. Standard Inference with a YOLOv8 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jNuL9dxgES3"
      },
      "source": [
        "- Instantiate a detection model by defining model weight path and other parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcqHL96DgES3"
      },
      "outputs": [],
      "source": [
        "detection_model = AutoDetectionModel.from_pretrained(\n",
        "    model_type='yolov8',\n",
        "    model_path=yolov8_model_path,\n",
        "    confidence_threshold=0.3,\n",
        "    device=\"cpu\", # or 'cuda:0'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQOyAI7HgES4"
      },
      "source": [
        "- Perform prediction by feeding the get_prediction function with an image path and a DetectionModel instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKsdqYiSgES4"
      },
      "outputs": [],
      "source": [
        "result = get_prediction(\"demo_data/train_ZRI_3030.JPG\", detection_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjKz46OegES4"
      },
      "source": [
        "- Or perform prediction by feeding the get_prediction function with a numpy image and a DetectionModel instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2O9Knw6gES4"
      },
      "outputs": [],
      "source": [
        "result = get_prediction(read_image(\"demo_data/train_ZRI_3030.JPG\"), detection_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8JPpWSAgES4"
      },
      "source": [
        "- Visualize predicted bounding boxes and masks over the original image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1qX8S79gES4"
      },
      "outputs": [],
      "source": [
        "result.export_visuals(export_dir=\"demo_data/\")\n",
        "\n",
        "Image(\"demo_data/prediction_visual.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JexnC_KfgES5"
      },
      "source": [
        "## 2. Sliced Inference with a YOLOv5 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJ0GI72DgES5"
      },
      "source": [
        "- To perform sliced prediction we need to specify slice parameters. In this example we will perform prediction over slices of 256x256 with an overlap ratio of 0.2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVH9Kj63gES5",
        "outputId": "0b877cc6-2a8b-4f6e-dd2a-c3d3976eeb94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing prediction on 48 number of slices.\n"
          ]
        }
      ],
      "source": [
        "result = get_sliced_prediction(\n",
        "    \"demo_data/train_ZRI_3030.JPG\",\n",
        "    detection_model,\n",
        "    slice_height = 640,\n",
        "    slice_width = 640,\n",
        "    overlap_height_ratio = 0.2,\n",
        "    overlap_width_ratio = 0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIKmMWE9gES5"
      },
      "source": [
        "- Visualize predicted bounding boxes and masks over the original image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LePYt2QLgES5"
      },
      "outputs": [],
      "source": [
        "result.export_visuals(export_dir=\"demo_data/\")\n",
        "\n",
        "Image(\"demo_data/prediction_visual.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFdX-Pg1gES5"
      },
      "source": [
        "## 3. Prediction Result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIURuseqgES5"
      },
      "source": [
        "- Predictions are returned as [sahi.prediction.PredictionResult](sahi/prediction.py), you can access the object prediction list as:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtpQ3vVagES5"
      },
      "outputs": [],
      "source": [
        "object_prediction_list = result.object_prediction_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lE3_yOJXgES6"
      },
      "outputs": [],
      "source": [
        "object_prediction_list[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3biXBc-gES6"
      },
      "source": [
        "- ObjectPrediction's can be converted to [COCO annotation](https://cocodataset.org/#format-data) format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAgUZuaxgES6"
      },
      "outputs": [],
      "source": [
        "result.to_coco_annotations()[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHnVE5YigES6"
      },
      "source": [
        "- ObjectPrediction's can be converted to [COCO prediction](https://github.com/i008/COCO-dataset-explorer) format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUSTHRB1gES6"
      },
      "outputs": [],
      "source": [
        "result.to_coco_predictions(image_id=1)[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mBiwjcfgES6"
      },
      "source": [
        "- ObjectPrediction's can be converted to [fiftyone](https://github.com/voxel51/fiftyone) detection format:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIXN7H-dgES7"
      },
      "source": [
        "## 4. Batch Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1bsE49hgES7"
      },
      "source": [
        "- Set model and directory parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdnXFTi9gES7"
      },
      "outputs": [],
      "source": [
        "model_type = \"yolov8\"\n",
        "model_path = yolov8_model_path\n",
        "model_device = \"cpu\" # or 'cuda:0'\n",
        "model_confidence_threshold = 0.4\n",
        "\n",
        "slice_height = 640\n",
        "slice_width = 640\n",
        "overlap_height_ratio = 0.2\n",
        "overlap_width_ratio = 0.2\n",
        "\n",
        "source_image_dir = \"demo_data/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DOWP-TbgES7"
      },
      "source": [
        "- Perform sliced inference on given folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrMCUY0agETA",
        "outputId": "99478d59-c77a-4deb-fc4a-2af684724872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4 listed files in folder: demo_data/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images:   0%|          | 0/4 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing prediction on 4 number of slices.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images:  25%|██▌       | 1/4 [00:01<00:04,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time is: 1394.52 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images:  25%|██▌       | 1/4 [00:01<00:04,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing prediction on 48 number of slices.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images:  25%|██▌       | 1/4 [00:15<00:04,  1.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time is: 13663.36 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images:  50%|█████     | 2/4 [00:17<00:19,  9.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing prediction on 48 number of slices.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images:  50%|█████     | 2/4 [00:30<00:19,  9.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time is: 13558.79 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images:  75%|███████▌  | 3/4 [00:31<00:12, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing prediction on 2 number of slices.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Performing inference on images: 100%|██████████| 4/4 [00:32<00:00,  8.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time is: 774.49 ms\n",
            "Prediction results are successfully exported to runs/predict/exp\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "predict(\n",
        "    model_type=model_type,\n",
        "    model_path=model_path,\n",
        "    model_device=model_device,\n",
        "    model_confidence_threshold=model_confidence_threshold,\n",
        "    source=source_image_dir,\n",
        "    slice_height=slice_height,\n",
        "    slice_width=slice_width,\n",
        "    overlap_height_ratio=overlap_height_ratio,\n",
        "    overlap_width_ratio=overlap_width_ratio,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "244b47d5824a96a4079632e50977464d968e13d2c337f65c905f8da81a0b4f95"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
